application:
  name: "SlideForge"
  version: "0.2.0"
  last_build: "2026-02-03 08:15 CET"
  host: "localhost"
  port: 8087
  author: "Gabor Nemet"
  copyright: "2026"
  engine: "Antigravity Engine"
  reference_doc_path: "docs/architecture/tech_stack.md"
  parser_rules_doc_path: "docs/implementation/development_workflow.md"


ai:
  active_provider: "gemini"
  providers:
    gemini:
      driver: "gemini"
      key: "" # Load from environment variable
      model: "" # Load from GEMINI_MODEL
      models: [] # Load from GEMINI_MODELS (comma separated)
      temperature: 0.1
    openai:
      driver: "openai"
      key: ""
      model: "gpt-4o"
      models: ["gpt-4o", "gpt-4o-mini", "o1-preview", "o1-mini"]
      temperature: 0.0
    claude:
      driver: "anthropic"
      key: ""
      model: "claude-sonnet-4-20250514"
      models: ["claude-sonnet-4-20250514", "claude-3-5-sonnet-20240620", "claude-3-opus-20240229", "claude-3-haiku-20240307"]
      temperature: 0.0
    local:
      driver: "openai_compatible"
      endpoint: "http://localhost:11434/v1"
      model: "llama3"
      models: ["sqlcoder", "llama3", "codellama", "mistral"]
      temperature: 0.1
    ollama:
      driver: "openai_compatible"
      endpoint: "http://localhost:11434/v1"
      model: "sqlcoder"
      models: ["sqlcoder", "llama3", "codellama", "mistral"]
      temperature: 0.0
      num_ctx: 4096
      repeat_penalty: 1.1
      top_p: 0.9
      top_k: 40
      max_tokens: 1024
    deepseek:
      driver: "openai_compatible"
      key: ""
      endpoint: "https://api.deepseek.com"
      model: "deepseek-chat"
      models: ["deepseek-chat", "deepseek-coder", "deepseek-reasoner"]
      temperature: 0.0
    mock:
      driver: "mock"
      model: "mock-model"

ldap:
  enabled: false
  host: "ldap.alig.hu"
  port: 389
  bind_dn: ""
  password: ""
  base_dn: ""
  prefix: ""
  postfix: "@alig.hu"
  search_filter: "(&(objectCategory=person)(objectClass=user))"
